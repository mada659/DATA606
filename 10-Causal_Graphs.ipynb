{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMkipwEVNBU9"
   },
   "source": [
    "## Causal Models\n",
    "\n",
    "Judea Pearl defines a causal model as an ordered triple ${\\displaystyle \\langle U,V,E\\rangle }$ , where U is a set of exogenous variables whose values are determined by factors outside the model; V is a set of endogenous variables whose values are determined by factors within the model; and E is a set of structural equations that express the value of each endogenous variable as a function of the values of the other variables in U and V.\n",
    "\n",
    "[Reference](https://en.wikipedia.org/wiki/Causal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFTOPRvqP0zW"
   },
   "source": [
    "## Ladder of Causation\n",
    "\n",
    "![image](http://lgmoneda.github.io/images/book-why/ladder-table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiS-0pETTRZR"
   },
   "source": [
    "## Mediator\n",
    "\n",
    "B is a mediator in that it mediates the change that A would otherwise have on C.\n",
    "\n",
    "${\\displaystyle A\\rightarrow B\\rightarrow C}$\n",
    "\n",
    "## Fork\n",
    "\n",
    "In forks, one cause has multiple effects. The two effects have a common cause. There exists a (non-causal) spurious correlation between A and C that can be eliminated by conditioning on B (for a specific value of B).[5]:114\n",
    "\n",
    "${\\displaystyle A\\leftarrow B\\rightarrow C}$\n",
    "\"Conditioning on B\" means \"given B\" (i.e., given a value of B).\n",
    "\n",
    "## Collider\n",
    "\n",
    "In colliders, multiple causes affect one outcome. Conditioning on B (for a specific value of B) often reveals a non-causal correlation between A and C. \n",
    "\n",
    "${\\displaystyle A\\rightarrow B\\leftarrow C}$\n",
    "\n",
    "### Exercise:\n",
    " Show that P(A,C)=P(A)P(C) using the graphical model of the collider\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eLrqrgLVXVp"
   },
   "source": [
    "## Independence conditions\n",
    "Independence conditions are rules for deciding whether two variables are independent of each other. Variables are independent if the values of one do not directly affect the values of the other. Multiple causal models can share independence conditions. For example, the models\n",
    "\n",
    "${\\displaystyle A\\rightarrow B\\rightarrow C}$\n",
    "and\n",
    "\n",
    "${\\displaystyle A\\leftarrow B\\rightarrow C}$\n",
    "have the same independence conditions, because conditioning on B leaves A and C independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ovFZ-UXz5uL"
   },
   "source": [
    "## Intervention\n",
    "\n",
    "\n",
    "${\\displaystyle P(Y|X)\\neq P(Y|do(X))}$\n",
    "\n",
    "If you intervene on a variable V, i.e., do(V), then you remove all the incoming arrows to the variable V and work with the mutilated graph\n",
    "\n",
    "![image](https://www.inference.vc/content/images/2019/01/Screen-Shot-2019-01-18-at-10.34.15-AM.png)\n",
    "\n",
    "![image](https://fabiandablander.com/assets/img/Seeing-vs-Doing-II.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQlZWFvE2YVs"
   },
   "source": [
    "## Backdoor Adjustment\n",
    "\n",
    "For analysing the causal effect of X on Y in a causal model we need to adjust for all confounder variables (deconfounding). \n",
    "\n",
    "Definition: a backdoor path from variable X to Y is any path from X to Y that starts with an arrow pointing to X.\n",
    "\n",
    "Definition: Given an ordered pair of variables (X,Y) in a model, a set of confounder variables Z satisfies the backdoor criterion if (1) no confounder variable Z is a descendent of X and (2) all backdoor paths between X and Y are blocked by the set of confounders.\n",
    "\n",
    "\n",
    "\n",
    "${\\displaystyle P(Y|do(X))=\\textstyle \\sum _{z}\\displaystyle P(Y|X,Z=z)P(Z=z)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOocsiKXaGTI"
   },
   "source": [
    "## Frontdoor adjustment\n",
    "\n",
    "Definition: \n",
    "\n",
    "a frontdoor path is a direct causal path for which data is available for all ${\\displaystyle z\\in Z}$, ${\\displaystyle Z}$ intercepts all directed paths ${\\displaystyle X}$ to ${\\displaystyle Y}$, there are no unblocked paths from ${\\displaystyle Z}$ to ${\\displaystyle Y}$, and all backdoor paths from ${\\displaystyle Z}$ to ${\\displaystyle Y}$ are blocked by ${\\displaystyle X}$. \n",
    "\n",
    "The following converts a do expression into a do-free expression by conditioning on the variables along the front-door path.[5]:226\n",
    "\n",
    "${\\displaystyle P(Y|do(X))=\\textstyle \\sum _{z}\\left[\\displaystyle P(Z=z|X)\\textstyle \\sum _{x}\\displaystyle P(Y|X=x,Z=z)P(X=x)\\right]}$\n",
    "\n",
    "Presuming data for these observable probabilities is available, the ultimate probability can be computed without an experiment, regardless of the existence of other confounding paths and without backdoor adjustment.\n",
    "\n",
    "![image](https://i.stack.imgur.com/k4Jhi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lg1CNC5ffcU"
   },
   "source": [
    "## Do calculus\n",
    "The do calculus is the set of manipulations that are available to transform one expression into another, with the general goal of transforming expressions that contain the do operator into expressions that do not.\n",
    "\n",
    "The set of rules is complete. An algorithm can determine whether, for a given model, a solution is computable in polynomial time.\n",
    "\n",
    "### Rule 1\n",
    "Rule 1 permits the addition or deletion of observations.\n",
    "\n",
    "${\\displaystyle P(Y|do(X),Z,W)=P(Y|do(X),Z)}$\n",
    "in the case that the variable set Z blocks all paths from W to Y and all arrows leading into X have been deleted\n",
    "\n",
    "## Rule 2\n",
    "Rule 2 permits the replacement of an intervention with an observation or vice versa.\n",
    "\n",
    "${\\displaystyle P(Y|do(X),Z)=P(Y|X,Z)}$\n",
    "in the case that Z satisfies the back-door criterion.\n",
    "\n",
    "### Rule 3\n",
    "Rule 3 permits the deletion or addition of interventions.\n",
    "\n",
    "{\\displaystyle P(Y|do(X))=P(Y)}$\n",
    "in the case where no causal paths connect X and Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JQMCBoClEH2"
   },
   "source": [
    "## Application of the Do Calculus\n",
    "\n",
    "![image](https://i.stack.imgur.com/jW6Nb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3dIDvc5ZBN_"
   },
   "source": [
    "## Counterfactuals\n",
    "\n",
    "[Reference](https://github.com/altdeep/causalML/blob/master/tutorials/3-counterfactual/counterfactuals_in_pyro.ipynb)\n",
    "\n",
    "This is an implementation of an example from Peters et al. 2017.\n",
    "\n",
    "Consider a treatment study, where a company introduced a new medicine for eyes.\n",
    "\n",
    "Suppose this is the true underlying model for the causal effect of Treatment $T$ ($T=1$ if the treatment was given) and the result $B$ ($B=1$ if the person goes blind).$$\n",
    "\\begin{align}\n",
    "N_T \\sim Ber(.5)\\\\ \n",
    "N_B \\sim Ber(.01) \\\\\n",
    " T := N_T \\\\\n",
    " B := T * N_B + (1-T)*(1-N_B) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Suppose patient with poor eyesight comes to the hospital and goes blind (B=1) after the doctor gives treatment (T=1).\n",
    "\n",
    "We can ask \"what would have happened had the doctor administered treatment T = 0?\"\n",
    "\n",
    "Here is the steps we follow to answer this counterfactual question.\n",
    "\n",
    "Retrieve noise variables given observation.\n",
    "\n",
    "We observed $B=T=1$. Plugging that to the equations above\n",
    "\n",
    "$$\\begin{align}\n",
    "1 = N_T\\\\\n",
    "1 = 1*N_B + (1-1)*(1-N_B)\n",
    "\\end{align}$$\n",
    "\n",
    "So, $N_T=1$ and $N_B = 1$\n",
    "\n",
    "Intervene on $T$. Put $T=0$, and solve for $B$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " T = 0\\\\\n",
    " B = 0 * 1 + (1-0)*(1-1) = 0 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Thus, by this model, person would not have gone blind if the treatment was not given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyxZsdT-gMX9"
   },
   "source": [
    "## Mediation\n",
    "\n",
    "How can we disentangle the Direct effect, Indirect effect, and Total effect?\n",
    "\n",
    "![image](https://lh3.googleusercontent.com/proxy/acghFDtZzq-gR7kkzlMUA8CIFogSL0aDJ8Pg9Et51R-m6cdHEUaw3S1yw-YLf-NaGBds34Ke7Rv5k5A)\n",
    "\n",
    "[Reference](https://en.wikipedia.org/wiki/Mediation_(statistics) )\n",
    "\n",
    " In particular, four types of effects have been defined for the transition from X = 0 to X = 1:\n",
    "\n",
    "(a) Total effect –\n",
    "\n",
    "${\\displaystyle TE=E[Y(1)-Y(0)]}$\n",
    "\n",
    "(b) Controlled direct effect -\n",
    "\n",
    "${\\displaystyle CDE(m)=E[Y(1,m)-Y(0,m)]}$\n",
    "\n",
    "(c) Natural direct effect -\n",
    "\n",
    "${\\displaystyle NDE=E[Y(1,M(0))-Y(0,M(0))]}$\n",
    "\n",
    "(d) Natural indirect effect\n",
    "\n",
    "${\\displaystyle NIE=E[Y(0,M(1))-Y(0,M(0))]}$\n",
    "\n",
    "Where E[ ] stands for expectation taken over the error terms.\n",
    "\n",
    "These effects have the following interpretations:\n",
    "\n",
    "-- TE measures the expected increase in the outcome Y as X changes from X=0 to X =1, while the mediator is allowed to track the change in X as dictated by the function M = g(X, ε2).\n",
    "\n",
    "--CDE measures the expected increase in the outcome Y as X changes from X = 0 to X = 1, while the mediator is fixed at a pre-specified level M = m uniformly over the entire population\n",
    "\n",
    "--NDE measures the expected increase in Y as X changes from X = 0 to X = 1, while setting the mediator variable to whatever value it would have obtained under X = 0, i.e., before the change.\n",
    "\n",
    "--NIE measures the expected increase in Y when the X is held constant, at X = 1, and M changes to whatever value it would have attained (for each individual) under X = 1.\n",
    "\n",
    "The difference TE-NDE measures the extent to which mediation is necessary for explaining the effect, while the NIE measures the extent to which mediation is sufficient for sustaining it.\n",
    "\n",
    "A controlled version of the indirect effect does not exist because there is no way of disabling the direct effect by fixing a variable to a constant.\n",
    "\n",
    "According to these definitions the total effect can be decomposed as a sum\n",
    "\n",
    "${\\displaystyle TE=NDE-NIE_{r}}$\n",
    "\n",
    "where NIEr stands for the reverse transition, from X = 1 to X = 0; it becomes additive in linear systems, where reversal of transitions entails sign reversal.\n",
    "\n",
    "The power of these definitions lies in their generality; they are applicable to models with arbitrary nonlinear interactions, arbitrary dependencies among the disturbances, and both continuous and categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dnc18X4kSXoI"
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "\n",
    "When the causal model is a plausible representation of reality and the backdoor criterion is satisfied, then partial regression coefficients can be used as (causal) path coefficients (for linear relationships) [Reference](https://en.wikipedia.org/wiki/Causal_model)\n",
    "\n",
    "The regression coefficient tells us the associational relationship of observational data. y = a + bx + cz. For a fixed value of z, a unit increase in x is associated with on average b increase in y. But we cannot say, in general, that changing x is associated with b increase in y. That is the difference between observation \"Seeing\" and interventional \"Doing\". The latter is the causal relationship. How do we know in a linear regression if the coefficient represents a causal impact? It depends on what z is. If z is a confounder, then b is a causal impact. If z is a collider or mediator, b is not a causal impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0uodXYYS2Dt",
    "outputId": "f9d609da-a487-409e-e966-256341c2d388"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LfkS6xlgd2I"
   },
   "source": [
    "## Confounder\n",
    "Let us simulate a data generating process. The first case is a common cause z of the two variables x and y. If we control for the confounding variable z, then then x and y become independent. \n",
    "\n",
    "Note that if z is a mediator between x and y and we control for z, then x and y become independent. Statistics alone cannot tell us which one is the right model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZsE5qT8gfED",
    "outputId": "bca9d827-65b4-4f26-a7bd-76e42efa72a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept   -0.004767\n",
      "x            1.214064\n",
      "dtype: float64\n",
      "Intercept   -0.010239\n",
      "x            0.004289\n",
      "z            2.988945\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fork (Confounder): x<-z->y\n",
    "z=np.random.normal(size=10000)\n",
    "x=2*z + np.random.normal(size=10000)\n",
    "y=3*z + np.random.normal(size=10000)\n",
    "data = pandas.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "mod7 = ols(\"y~x\", data).fit()\n",
    "print(mod7.params)\n",
    "mod8 = ols(\"y~x+z\", data).fit()\n",
    "print(mod8.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPIGcU4ggoAJ"
   },
   "source": [
    "## Mediator\n",
    "The second case is a mediator z between x and y. But we also add a direct path from x to y.\n",
    "If we control for z, we can meaure the direct causal impact of x on y. Otherwise we have the total impact (direct + indirect) of x on y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zZvlx3kgrpc",
    "outputId": "029c033e-5617-4cbb-b8a1-a34019855437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept     0.033468\n",
      "x            11.014335\n",
      "dtype: float64\n",
      "Intercept   -9.020562e-17\n",
      "x            5.000000e+00\n",
      "z            3.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Mediator (direct and indirect causal impact): x->z->y and x->y\n",
    "x=np.random.normal(size=10000)\n",
    "z = 2*x + np.random.normal(size=10000)\n",
    "y = 3*z + 5*x\n",
    "data = pandas.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "mod5 = ols(\"y~x\", data).fit()\n",
    "print(mod5.params)\n",
    "mod6 = ols(\"y~x+z\", data).fit()\n",
    "print(mod6.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOU0QixjgwN5"
   },
   "source": [
    "## Collider\n",
    "\n",
    "The third case is a common effect z of the two variables x and y. The variables x and y are indpendent. If we control for the variable z, then x and y become dependent. \n",
    "This shows that controlling for more variables can create a bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivT4bmy4gxSN",
    "outputId": "01a249d2-2afa-4fe8-dd24-dbf9acce459e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept   -0.018117\n",
      "x           -0.004741\n",
      "dtype: float64\n",
      "Intercept    9.497611e-17\n",
      "x           -1.000000e+00\n",
      "z            1.000000e+00\n",
      "dtype: float64\n",
      "Intercept   -6.071532e-18\n",
      "x            1.000000e+00\n",
      "y            1.000000e+00\n",
      "dtype: float64\n",
      "Intercept   -0.018117\n",
      "x            0.995259\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Collider:  x->z<-y. Controlling for Z introduces bias\n",
    "x=np.random.normal(size=10000)\n",
    "y=np.random.normal(size=10000)\n",
    "z=x+y\n",
    "data = pandas.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "mod1 = ols(\"y~x\", data).fit()\n",
    "print(mod1.params)\n",
    "mod2 = ols(\"y~x+z\", data).fit()\n",
    "print(mod2.params)\n",
    "mod3 = ols(\"z~x+y\", data).fit() # The regression coeffient of z with respect to x does not change if we add/remove y,\n",
    "                                #since x and y are independent \n",
    "print(mod3.params)\n",
    "mod4 = ols(\"z~x\", data).fit() # it is no different than mod3\n",
    "print(mod4.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZhC2bIpM9bc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Causal_Graphs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
